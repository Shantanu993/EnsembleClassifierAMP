{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdULAr6bKnlx"
   },
   "source": [
    "**LOADING THE DATASET AND ANALYZING IT**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SywOGrWNpWyA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mo1pWnrGrrCZ",
    "outputId": "6d93aa97-9142-44a0-a95c-77a6b12dcf5c"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('/content/general_amps.xlsx', sheet_name='general_amps')\n",
    "print(df.head()) #prints the first 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CfOofNpus9JA",
    "outputId": "dcec9150-f164-44c7-ade8-34012e06982d"
   },
   "outputs": [],
   "source": [
    "print(df.info())         # Check data types and non-null counts\n",
    "print(df.describe())     # Get a summary of numerical features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwdyQRk5K47U"
   },
   "source": [
    "**Dropping Columns which are not required**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2qM3gottjzL",
    "outputId": "f6a51398-8101-4185-8be3-716a6c352675"
   },
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "columns_to_drop = [\n",
    "    'DRAMP_ID',\n",
    "    'Swiss_Prot_Entry',\n",
    "    'Pubmed_ID',\n",
    "    'Name',\n",
    "    'Comments',\n",
    "    'Reference',\n",
    "    'Author',\n",
    "    'Title',\n",
    "    'PDB_ID',\n",
    "    'Other_Modifications',\n",
    "    'N-terminal_Modification',\n",
    "    'C-terminal_Modification'\n",
    "]\n",
    "\n",
    "# Drop columns\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Check the DataFrame after dropping columns\n",
    "print(\"Remaining columns after dropping unnecessary ones:\\n\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJIU5bGpuVZM",
    "outputId": "4500a366-3420-46ab-b6a8-a72044fba4d3"
   },
   "outputs": [],
   "source": [
    "# Check the actual column names\n",
    "print(\"Current columns in the DataFrame:\\n\", df.columns.tolist())\n",
    "\n",
    "print(df.info())         # Check data types and non-null counts\n",
    "print(df.describe())     # Get a summary of numerical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Vx44AoBPXWg",
    "outputId": "3b366e8d-1a68-4776-bf89-51405e86239f"
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the 'Sequence' column\n",
    "df.dropna(subset=['Sequence'], inplace=True)\n",
    "\n",
    "# Fill missing values in categorical columns with the most frequent value (mode)\n",
    "categorical_columns = ['Family', 'Gene', 'Protein_existence', 'Structure',\n",
    "                       'Hemolytic_activity', 'Linear/Cyclic/Branched', 'Stereochemistry',\n",
    "                       'Cytotoxicity', 'Binding_Traget']\n",
    "\n",
    "# Fill categorical columns with mode (most frequent value)\n",
    "for column in categorical_columns:\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "\n",
    "# Check for remaining missing values to confirm\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Display columns with missing values if any\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Final check of the dataset\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lVv-oBaQs9t",
    "outputId": "978f217f-d0d9-4c95-ba2e-862d81c05909"
   },
   "outputs": [],
   "source": [
    "# Get the count of each unique entry in the 'Activity' column\n",
    "activity_counts = df['Activity'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(activity_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaHEqFr3LD5Z"
   },
   "source": [
    "**PREPROCESSING THE DATASET**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPeAXWfgRpmt",
    "outputId": "41f3241b-026b-4466-d14f-b26e249125bd"
   },
   "outputs": [],
   "source": [
    "# Step 1: Define a function to clean strings\n",
    "def clean_string(s):\n",
    "    if isinstance(s, str):  # Check if the value is a string\n",
    "        return ' '.join(s.split()).lower()  # Remove extra spaces and convert to lowercase\n",
    "    return s  # Return the value as is if it's not a string\n",
    "\n",
    "# Step 2: Apply the function to all object-type columns in the DataFrame except for 'Sequence'\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    if column != 'Sequence':  # Exclude the 'Sequence' column\n",
    "        df[column] = df[column].apply(clean_string)\n",
    "\n",
    "# Step 3: Verify the transformation\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9P1fUDQSLAz",
    "outputId": "b470ee63-e97c-4a8e-bdf7-e24aafb8058c"
   },
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and already loaded\n",
    "# Define a function to categorize activities\n",
    "def categorize_activity(activity):\n",
    "    # Convert to lower case and check for keywords\n",
    "    activity = activity.lower()\n",
    "    antimicrobial_keywords = ['antimicrobial']\n",
    "\n",
    "    # Check if any antimicrobial keyword is in the activity\n",
    "    if any(keyword in activity for keyword in antimicrobial_keywords):\n",
    "        return 'Antimicrobial'\n",
    "    else:\n",
    "        return 'Non-Antimicrobial'\n",
    "\n",
    "# Apply the function to the Activity column\n",
    "df['Activity'] = df['Activity'].apply(categorize_activity)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrfikWLjLL8x"
   },
   "source": [
    "**Getting the count of target variables in the 'Activity' column**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGTq6Q6ZS3ek",
    "outputId": "959b1654-7f9a-42e9-c226-c5571923391e"
   },
   "outputs": [],
   "source": [
    "print(df['Activity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f-dSFXwTCs9",
    "outputId": "f8deae21-5a08-4634-9cc6-85d5de34f080"
   },
   "outputs": [],
   "source": [
    "print(df['Activity'].unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NudHj0qtLZlx"
   },
   "source": [
    "**Checking the current columns in the dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKP_jQ08UYxX",
    "outputId": "73c3ee68-345d-4165-89a1-fd9d249fedbf"
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNcjFGRkvzji",
    "outputId": "8fb9614b-bb5d-46a0-d59c-26e9bddf0be0"
   },
   "outputs": [],
   "source": [
    "# Display the unique non-antimicrobial entries\n",
    "non_antimicrobial_entries = df[df['Activity'] == 'Non-Antimicrobial']\n",
    "print(non_antimicrobial_entries['Activity'].unique())\n",
    "\n",
    "# Display a sample of non-antimicrobial entries\n",
    "print(non_antimicrobial_entries.sample(10))  # Adjust the number to see more or fewer entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bIPb3VjHbEVg",
    "outputId": "974e6209-a75e-4376-bdfd-c33185e68734"
   },
   "outputs": [],
   "source": [
    "# Count unique non-antimicrobial entries\n",
    "unique_non_antimicrobials = df[df['Activity'] == 'Non-Antimicrobial']['Source'].unique()\n",
    "print(f\"Unique Non-Antimicrobial Sources: {len(unique_non_antimicrobials)}\")\n",
    "print(unique_non_antimicrobials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXheMqgRb2Tr",
    "outputId": "f1b00e6b-622e-4df0-8fd2-1771d6c1b844"
   },
   "outputs": [],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcI8-aNALiLz"
   },
   "source": [
    "**Checking for Null values**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3cHblVWdLFz",
    "outputId": "0c01dd85-76fc-486e-ad35-2caff7380aac"
   },
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "not_found_counts = df.apply(lambda x: (x == 'not found').sum())\n",
    "print(\"The no of not found counts:\")\n",
    "# Display the counts\n",
    "print(not_found_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCmfl9KjLnF_"
   },
   "source": [
    "**Dropping again unecessary columns, extracting features**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyBjO9Dfe_uD",
    "outputId": "18ba455c-6ca1-4b13-c5ed-30d0a2b7f08e"
   },
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "columns_to_drop = [\n",
    "    'Binding_Traget',\n",
    "    'Structure_Description',\n",
    "    'Gene',\n",
    "    'Family',\n",
    "    'Structure',\n",
    "    'Cytotoxicity'\n",
    "]\n",
    "\n",
    "# Drop columns\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Check the DataFrame after dropping columns\n",
    "print(\"Remaining columns after dropping unnecessary ones:\\n\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zCxwAirg4JW",
    "outputId": "619422b1-04b1-44f9-c863-93acb71d33c3"
   },
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named 'df'\n",
    "missing_values_count = df.isnull().sum()\n",
    "\n",
    "# Display the counts of missing values\n",
    "print(missing_values_count)\n",
    "\n",
    "print(df['Activity'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pekCeoN9S6SR"
   },
   "source": [
    "**SOME DATA ANALYSIS AND VISUALIZATION**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "MP1hTlBJQaYg",
    "outputId": "cfad4b55-f826-4f0e-f0b0-5bc271bb36ca"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the distribution of antimicrobial vs non-antimicrobial peptides\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='Activity', hue='Activity', palette='Set2', legend=False)\n",
    "plt.title('Distribution of Antimicrobial vs Non-Antimicrobial Peptides')\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "YPrcZHcVQzcI",
    "outputId": "81d5e372-5b8b-4bb7-ff6c-2399aed8681a"
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of peptide sequence lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Sequence_Length'], bins=30, kde=True, color='blue')\n",
    "plt.title('Distribution of Peptide Sequence Lengths')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "sTKNnReBQ5Sw",
    "outputId": "5905e8b3-e31c-4e15-a46f-76dd0b8f7c11"
   },
   "outputs": [],
   "source": [
    "# Boxplot for sequence length based on activity type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='Activity', y='Sequence_Length', hue='Activity', palette='coolwarm', dodge=False)\n",
    "plt.title('Sequence Length Distribution by Activity Type')\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Sequence Length')\n",
    "plt.legend([],[], frameon=False)  # Remove the legend as it's not needed\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "xpV-gEcwT0G7",
    "outputId": "7cfd3206-9a1e-416e-8faa-53421f28fec6"
   },
   "outputs": [],
   "source": [
    "# Pie chart for Linear, Cyclic, and Branched Peptides using a legend\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Get the value counts for Linear/Cyclic/Branched peptides\n",
    "peptide_counts = df['Linear/Cyclic/Branched'].value_counts()\n",
    "\n",
    "# Create an explode list with a length equal to the number of unique categories\n",
    "explode = [0.1] * len(peptide_counts)  # Slightly separate all slices\n",
    "\n",
    "# Define colors dynamically based on the number of unique categories\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral'] * (len(peptide_counts) // 3 + 1)  # Ensure enough colors\n",
    "\n",
    "# Create the pie chart\n",
    "plt.pie(\n",
    "    peptide_counts,\n",
    "    autopct='%1.1f%%',          # Display percentages\n",
    "    colors=colors[:len(peptide_counts)],  # Use the appropriate number of colors\n",
    "    startangle=90,              # Start at 90 degrees to avoid overlap\n",
    "    explode=explode,            # Slightly separate the slices\n",
    "    shadow=True,                # Add shadow for better visibility\n",
    "    textprops=dict(color=\"w\")   # Set text color for better contrast\n",
    ")\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(peptide_counts.index, title=\"Peptide Types\", loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.title('Proportion of Linear, Cyclic, and Branched Peptides')\n",
    "plt.ylabel('')  # Remove the y-label for a cleaner look\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N70eQkroLzvg"
   },
   "source": [
    "**Splitting the dataset and applying SMOTE technique to handle imbalances**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRIgM0h4ieYP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample DataFrame (replace this with your actual DataFrame)\n",
    "# df = ...\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df[['Sequence', 'Sequence_Length', 'Source', 'Protein_existence',\n",
    "         'Target_Organism', 'Hemolytic_activity',\n",
    "         'Linear/Cyclic/Branched', 'Stereochemistry']]\n",
    "y = df['Activity']\n",
    "\n",
    "# Convert 'Sequence' to k-mer representation\n",
    "k = 3  # Change k for different lengths\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(k, k))\n",
    "X_kmers = vectorizer.fit_transform(X['Sequence']).toarray()\n",
    "\n",
    "# Create a DataFrame from k-mer features\n",
    "kmers_df = pd.DataFrame(X_kmers, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Combine k-mer features with other features\n",
    "X_combined = pd.concat([kmers_df, X[['Sequence_Length', 'Source', 'Protein_existence',\n",
    "                                       'Target_Organism', 'Hemolytic_activity',\n",
    "                                       'Linear/Cyclic/Branched', 'Stereochemistry']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "X_encoded = pd.get_dummies(X_combined, columns=['Source', 'Protein_existence', 'Target_Organism',\n",
    "                                                'Hemolytic_activity', 'Linear/Cyclic/Branched',\n",
    "                                                'Stereochemistry'], drop_first=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Now you can train your model on X_resampled and y_resampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaMl8b9wL9FL"
   },
   "source": [
    "**Checking size of Dataset after SMOTE**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IujwO2ESjO1z",
    "outputId": "1bc013b0-2da7-47ce-f6ad-b14923eb4243"
   },
   "outputs": [],
   "source": [
    "# Check the sizes of the datasets after SMOTE\n",
    "print(f'Size of X_train after SMOTE: {X_resampled.shape}')\n",
    "print(f'Size of y_train after SMOTE: {y_resampled.shape}')\n",
    "print(f'Size of X_test: {X_test.shape}')\n",
    "print(f'Size of y_test: {y_test.shape}')\n",
    "\n",
    "\n",
    "class_counts = y_train.value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sg4JxpYtj3Bz"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XQxYOC2MDH7"
   },
   "source": [
    "**Balanced Datas for both the classes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZPnxZCQj9e0",
    "outputId": "e13c911d-c0d0-40f3-dac6-87a4ccb6ea6d"
   },
   "outputs": [],
   "source": [
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCBMX9b1MJcH"
   },
   "source": [
    "**Training the model and applying Ensemble Voting Classifier method**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHbHM3aJlcqu",
    "outputId": "e2f72a8d-6c69-459c-8a8b-3cff58b516e1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Standardize the feature set\n",
    "scaler = StandardScaler()\n",
    "X_resampled = scaler.fit_transform(X_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the base models\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create the Voting Classifier with weights\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('logistic_regression', log_reg),\n",
    "    ('random_forest', rf_classifier)\n",
    "], voting='soft', weights=[1, 2])  # Adjust weights as necessary\n",
    "\n",
    "# Train the Voting Classifier\n",
    "voting_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylyUf70yevTI"
   },
   "source": [
    "**MODEL EVALUATION and the ROC Curve and Confusion Matrix**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "14I-6PQIeu82",
    "outputId": "34ed48ca-4357-43ca-9c34-5104924465ec"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Standardize the feature set\n",
    "scaler = StandardScaler()\n",
    "X_resampled = scaler.fit_transform(X_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_resampled_encoded = le.fit_transform(y_resampled)  # Encode training labels\n",
    "y_test_encoded = le.transform(y_test)  # Encode test labels\n",
    "\n",
    "# Initialize the base models\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create the Voting Classifier with weights\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('logistic_regression', log_reg),\n",
    "    ('random_forest', rf_classifier)\n",
    "], voting='soft', weights=[1, 2])  # Adjust weights as necessary\n",
    "\n",
    "# Train the Voting Classifier\n",
    "voting_classifier.fit(X_resampled, y_resampled_encoded)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "y_pred_proba = voting_classifier.predict_proba(X_test)[:, 1]  # Get probabilities for positive class\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test_encoded, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_encoded, y_pred))\n",
    "\n",
    "# Function to plot ROC Curve\n",
    "def plot_roc_curve(y_true, y_scores, model_name):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot Confusion Matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    disp.plot(cmap='Blues', ax=plt.gca())\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC Curve for Voting Classifier\n",
    "plot_roc_curve(y_test_encoded, y_pred_proba, 'Voting Classifier')\n",
    "# Plot Confusion Matrix for Voting Classifier\n",
    "plot_confusion_matrix(y_test_encoded, y_pred, 'Voting Classifier')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxpmGIllMcdc"
   },
   "source": [
    "**Now trying again with Random Under Sampler method for better accuracy reducing the majority class and increasing the data for minority simultaneously**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jb7B_U0eoS1N",
    "outputId": "49c6441f-168c-4888-b6d5-2d6365efc2d4"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Step 1: Apply SMOTE to the training data to increase Non-Antimicrobial class\n",
    "smote = SMOTE(sampling_strategy={ 'Non-Antimicrobial': 3500 }, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 2: Apply Random UnderSampling to Antimicrobial class to reduce it to 4000\n",
    "rus = RandomUnderSampler(sampling_strategy={ 'Antimicrobial': 3500 }, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(y_resampled.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "481Fo7maMngm"
   },
   "source": [
    "**Again checking the value count in each class**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WoNSJTL6pdTh",
    "outputId": "09d93372-7a3c-4cad-c5f9-302f51fa9383"
   },
   "outputs": [],
   "source": [
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL06VlLAMwBQ"
   },
   "source": [
    "**Now implementing using CATBoost for better efficiency**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3MoeiEtqtve",
    "outputId": "511e9514-086e-484f-d510-69259f3540be"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na_0VPqCM64S"
   },
   "source": [
    "**Training the model again using Random Forest, Logistic Regression and CatBoost Classifier**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GblkYDrSNRuG"
   },
   "source": [
    "**Also adding weights to model for better performing for minority class dataset, here 'Non-Antimicrobial'**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbyDM5c1pjY3",
    "outputId": "0082bd1f-ec71-4965-c86b-8a776c86f8cc"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "# Initialize models with class weights\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "log_reg_model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "catboost_model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6,\n",
    "                                     class_weights=[1, 5], verbose=0)  # Adjust class_weights as needed\n",
    "\n",
    "# Create a Voting Classifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('rf', rf_model),\n",
    "    ('log_reg', log_reg_model),\n",
    "    ('catboost', catboost_model)\n",
    "], voting='soft')  # Use 'soft' for probability-based voting\n",
    "\n",
    "# Train Voting Classifier\n",
    "voting_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_voting = voting_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate Voting Classifier\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "classification_rep_voting = classification_report(y_test, y_pred_voting)\n",
    "\n",
    "print(\"Model: Voting Classifier\")\n",
    "print(f\"Accuracy: {accuracy_voting}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_voting)\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Optionally, evaluate individual models as well\n",
    "for model_name, model in zip(['Random Forest', 'Logistic Regression', 'CatBoost'],\n",
    "                               [rf_model, log_reg_model, catboost_model]):\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_rep)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGDtn7p9d-BC"
   },
   "source": [
    "**MODEL EVALUATION and the ROC Curve and Confusion Matrix of the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-yydqyFdaprK",
    "outputId": "1b565805-84f3-4061-e6bf-8bb26644d30d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_resampled_encoded = le.fit_transform(y_resampled)  # Encode training labels\n",
    "y_test_encoded = le.transform(y_test)  # Encode test labels\n",
    "\n",
    "# Fit models using encoded labels\n",
    "rf_model.fit(X_resampled, y_resampled_encoded)\n",
    "log_reg_model.fit(X_resampled, y_resampled_encoded)\n",
    "catboost_model.fit(X_resampled, y_resampled_encoded)\n",
    "\n",
    "# Create a Voting Classifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('rf', rf_model),\n",
    "    ('log_reg', log_reg_model),\n",
    "    ('catboost', catboost_model)\n",
    "], voting='soft')  # Use 'soft' for probability-based voting\n",
    "\n",
    "# Train Voting Classifier\n",
    "voting_classifier.fit(X_resampled, y_resampled_encoded)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_voting = voting_classifier.predict(X_test)\n",
    "y_pred_proba_voting = voting_classifier.predict_proba(X_test)[:, 1]  # Get probabilities for positive class\n",
    "\n",
    "# Evaluate Voting Classifier\n",
    "accuracy_voting = accuracy_score(y_test_encoded, y_pred_voting)\n",
    "classification_rep_voting = classification_report(y_test_encoded, y_pred_voting)\n",
    "\n",
    "print(\"Model: Voting Classifier\")\n",
    "print(f\"Accuracy: {accuracy_voting}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_voting)\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Function to plot ROC Curve\n",
    "def plot_roc_curve(y_true, y_scores, model_name):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot Confusion Matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    disp.plot(cmap='Blues', ax=plt.gca())\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "# ROC Curve for Voting Classifier\n",
    "plot_roc_curve(y_test_encoded, y_pred_proba_voting, 'Voting Classifier')\n",
    "# Confusion Matrix for Voting Classifier\n",
    "plot_confusion_matrix(y_test_encoded, y_pred_voting, 'Voting Classifier')\n",
    "\n",
    "# Optionally, evaluate individual models as well\n",
    "for model_name, model in zip(['Random Forest', 'Logistic Regression', 'CatBoost'],\n",
    "                               [rf_model, log_reg_model, catboost_model]):\n",
    "    # Get predictions and probabilities\n",
    "    model.fit(X_resampled, y_resampled_encoded)  # Fit the model with encoded labels\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Get probabilities for positive class\n",
    "\n",
    "    # ROC Curve\n",
    "    plot_roc_curve(y_test_encoded, y_pred_proba, model_name)\n",
    "    # Confusion Matrix\n",
    "    plot_confusion_matrix(y_test_encoded, y_pred, model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYHRtSFeNxhx"
   },
   "source": [
    "**Reducing the majority class equal to the minority class**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LPgwFzTqtKPd",
    "outputId": "90463f22-9969-4730-ab22-6c0ece448ed4"
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Initialize the undersampler\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "\n",
    "# Fit and resample the training data\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(\"Class distribution after undersampling:\")\n",
    "print(y_resampled.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XayYV_4EtSCE",
    "outputId": "6f52afe2-2358-42de-fb6b-fc1e40810165"
   },
   "outputs": [],
   "source": [
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPgUzgOSN_Fm"
   },
   "source": [
    "**Again training the model with the new values of the target class**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x2P-udO5tNTW",
    "outputId": "123d5d61-90cd-4c22-c5dd-14934d8fcae5"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "# Initialize models with class weights\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "log_reg_model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "catboost_model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6,\n",
    "                                     class_weights=[1, 5], verbose=0)  # Adjust class_weights as needed\n",
    "\n",
    "# Create a Voting Classifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('rf', rf_model),\n",
    "    ('log_reg', log_reg_model),\n",
    "    ('catboost', catboost_model)\n",
    "], voting='soft')  # Use 'soft' for probability-based voting\n",
    "\n",
    "# Train Voting Classifier\n",
    "voting_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_voting = voting_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate Voting Classifier\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "classification_rep_voting = classification_report(y_test, y_pred_voting)\n",
    "\n",
    "print(\"Model: Voting Classifier\")\n",
    "print(f\"Accuracy: {accuracy_voting}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_voting)\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Optionally, evaluate individual models as well\n",
    "for model_name, model in zip(['Random Forest', 'Logistic Regression', 'CatBoost'],\n",
    "                               [rf_model, log_reg_model, catboost_model]):\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_rep)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4dpQrN9ecQW"
   },
   "source": [
    "**MODEL EVALUATION and the ROC Curve and Confusion Matrix of the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4ahO2SIIX8I5",
    "outputId": "85771d2e-625d-460c-ccf8-32cc84ed847a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_resampled)  # Encode training labels\n",
    "y_test_encoded = le.transform(y_test)  # Encode test labels\n",
    "\n",
    "# Fit models using encoded labels\n",
    "rf_model.fit(X_resampled, y_train_encoded)\n",
    "log_reg_model.fit(X_resampled, y_train_encoded)\n",
    "catboost_model.fit(X_resampled, y_train_encoded)\n",
    "\n",
    "# Create the Voting Classifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('rf', rf_model),\n",
    "    ('log_reg', log_reg_model),\n",
    "    ('catboost', catboost_model)\n",
    "], voting='soft')  # Use 'soft' for probability-based voting\n",
    "\n",
    "# Train Voting Classifier\n",
    "voting_classifier.fit(X_resampled, y_train_encoded)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_voting = voting_classifier.predict(X_test)\n",
    "y_pred_proba_voting = voting_classifier.predict_proba(X_test)[:, 1]  # Get the probabilities for the positive class\n",
    "\n",
    "# Function to plot ROC Curve (updated to handle label encoding)\n",
    "def plot_roc_curve(y_true, y_scores, model_name):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Confusion Matrix function remains the same\n",
    "\n",
    "# ROC Curve for Voting Classifier\n",
    "plot_roc_curve(y_test_encoded, y_pred_proba_voting, 'Voting Classifier')\n",
    "# Confusion Matrix for Voting Classifier\n",
    "plot_confusion_matrix(y_test_encoded, y_pred_voting, 'Voting Classifier')\n",
    "\n",
    "# Evaluate individual models\n",
    "models = [('Voting Classifier', voting_classifier),\n",
    "          ('Random Forest', rf_model),\n",
    "          ('Logistic Regression', log_reg_model),\n",
    "          ('CatBoost', catboost_model)]\n",
    "\n",
    "for model_name, model in models:\n",
    "    # Get predictions and probabilities\n",
    "    if model_name == 'Voting Classifier':\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]  # Get the probabilities for the positive class\n",
    "\n",
    "    # ROC Curve\n",
    "    plot_roc_curve(y_test_encoded, y_pred_proba, model_name)\n",
    "    # Confusion Matrix\n",
    "    plot_confusion_matrix(y_test_encoded, y_pred, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQglL42zX8ID"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlyL7ERkOPdM"
   },
   "source": [
    "**Since undersmapling did not provide good results with overfitting again reducing the majority class and increasing the minority class to 3000 values each**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlS1Cx55tuqL",
    "outputId": "5f17fcba-db56-4800-ccf1-4698d54de245"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Step 1: Apply SMOTE to the training data to increase Non-Antimicrobial class\n",
    "smote = SMOTE(sampling_strategy={ 'Non-Antimicrobial': 3000 }, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 2: Apply Random UnderSampling to Antimicrobial class to reduce it to 4000\n",
    "rus = RandomUnderSampler(sampling_strategy={ 'Antimicrobial': 3000 }, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(y_resampled.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLK_DrzbOccY"
   },
   "source": [
    "**Some data visualization after changing the data values**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nR_VcYcU-ugQ",
    "outputId": "a0f6f8d7-beb0-4643-9561-71f754cdb6b7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize class distribution before SMOTE\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x=y)\n",
    "plt.title('Class Distribution Before SMOTE')\n",
    "plt.xlabel('Activity Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Visualize class distribution after SMOTE\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x=y_resampled)\n",
    "plt.title('Class Distribution After SMOTE')\n",
    "plt.xlabel('Activity Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "IZQW_4gP-7yG",
    "outputId": "ff97a392-577a-4528-ac32-5c17ef2e883e"
   },
   "outputs": [],
   "source": [
    "# Get the sum of occurrences of each k-mer\n",
    "kmers_freq = kmers_df.sum(axis=0).sort_values(ascending=False)\n",
    "\n",
    "# Plot top 20 most frequent k-mers\n",
    "plt.figure(figsize=(10, 6))\n",
    "kmers_freq[:20].plot(kind='bar', color='skyblue')\n",
    "plt.title(f'Top 20 Most Frequent {k}-mers')\n",
    "plt.xlabel(f'{k}-mers')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUpizy2ZOniE"
   },
   "source": [
    "******\\*\\*******\\*\\*\\*\\*******\\*\\*******\\*\\*\\*\\*******\\*\\*******\\*\\*\\*\\*******\\*\\*******THE END**\\*\\***\\*\\***\\*\\***\\***\\*\\***\\*\\***\\*\\***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX-fEuhrP65l"
   },
   "source": [
    "**HYPERPARAMETER TUNING OF THE MODEL**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlE8AGVzu-u6",
    "outputId": "0ced3120-5f17-4991-8909-9c090e7eab52"
   },
   "outputs": [],
   "source": [
    "!pip install bayesian-optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZW6Y84Teub5A",
    "outputId": "88ee1ae0-04ab-4fba-ab7f-463328035a13"
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming X_resampled and y_resampled are the full-sized training dataset\n",
    "\n",
    "# Step 1: Define Bayesian Optimization functions\n",
    "\n",
    "# Random Forest Optimization\n",
    "def rf_evaluate(n_estimators, max_depth, min_samples_split):\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=int(n_estimators),\n",
    "        max_depth=int(max_depth),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    scores = cross_val_score(rf, X_resampled, y_resampled, cv=3, scoring='f1_weighted')  # Keep cv=3 for speed\n",
    "    return scores.mean()\n",
    "\n",
    "# CatBoost Optimization with early stopping\n",
    "def catboost_evaluate(iterations, learning_rate, depth):\n",
    "    catboost = CatBoostClassifier(\n",
    "        iterations=int(iterations),\n",
    "        learning_rate=learning_rate,\n",
    "        depth=int(depth),\n",
    "        early_stopping_rounds=50,  # Early stopping to reduce unnecessary iterations\n",
    "        verbose=0\n",
    "    )\n",
    "    scores = cross_val_score(catboost, X_resampled, y_resampled, cv=3, scoring='f1_weighted')\n",
    "    return scores.mean()\n",
    "\n",
    "# Step 2: Define the parameter bounds for optimization\n",
    "rf_bounds = {\n",
    "    'n_estimators': (50, 150),  # Reduced range for faster search\n",
    "    'max_depth': (5, 15),\n",
    "    'min_samples_split': (2, 8)\n",
    "}\n",
    "\n",
    "catboost_bounds = {\n",
    "    'iterations': (100, 500),  # Limited range for iterations\n",
    "    'learning_rate': (0.05, 0.2),  # Focus on a smaller range\n",
    "    'depth': (3, 8)  # Reduced depth for faster training\n",
    "}\n",
    "\n",
    "# Step 3: Perform Bayesian Optimization for Random Forest\n",
    "rf_optimizer = BayesianOptimization(f=rf_evaluate, pbounds=rf_bounds, random_state=42)\n",
    "rf_optimizer.maximize(init_points=3, n_iter=5)  # Fewer initial points and iterations\n",
    "\n",
    "# Step 4: Get the best parameters for Random Forest\n",
    "best_rf_params = rf_optimizer.max['params']\n",
    "print(\"Best parameters for Random Forest: \", best_rf_params)\n",
    "\n",
    "# Step 5: Train Random Forest with best parameters\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=int(best_rf_params['n_estimators']),\n",
    "    max_depth=int(best_rf_params['max_depth']),\n",
    "    min_samples_split=int(best_rf_params['min_samples_split']),\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 6: Perform Bayesian Optimization for CatBoost\n",
    "catboost_optimizer = BayesianOptimization(f=catboost_evaluate, pbounds=catboost_bounds, random_state=42)\n",
    "catboost_optimizer.maximize(init_points=3, n_iter=5)  # Reduced iterations for speed\n",
    "\n",
    "# Step 7: Get the best parameters for CatBoost\n",
    "best_catboost_params = catboost_optimizer.max['params']\n",
    "print(\"Best parameters for CatBoost: \", best_catboost_params)\n",
    "\n",
    "# Step 8: Train CatBoost with best parameters\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=int(best_catboost_params['iterations']),\n",
    "    learning_rate=best_catboost_params['learning_rate'],\n",
    "    depth=int(best_catboost_params['depth']),\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Step 9: Create the Voting Classifier\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('svm', SVC(class_weight='balanced', probability=True, random_state=42)),  # SVM kept as-is\n",
    "        ('catboost', catboost_model)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Step 10: Train the Voting Classifier\n",
    "voting_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Step 11: Evaluate the model\n",
    "y_pred = voting_model.predict(X_test)\n",
    "\n",
    "# Step 12: Print accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yC7Q6Flc5M4M",
    "outputId": "709d455c-c7ad-41fa-e731-a8d929af1f9b"
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XCaNOty088ei",
    "outputId": "f7797f1c-d244-42d6-8297-26af8694a8b7"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2UM3B9Y_BXy",
    "outputId": "2198b46d-d70f-4444-ad72-cb0eaed9c428"
   },
   "outputs": [],
   "source": [
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8A9bWUxEDG3A",
    "outputId": "bc690d47-deb8-4866-a3a2-63f6a763d3b8"
   },
   "outputs": [],
   "source": [
    "non_antimicrobial_rows = df[df['Activity'] == 'Non-antimicrobial']\n",
    "\n",
    "# Display the result\n",
    "print(non_antimicrobial_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XzFE1G2Drrp",
    "outputId": "f7c22209-b416-401f-d584-028344679ddd"
   },
   "outputs": [],
   "source": [
    "print(df[df['Activity']=='Non-Antimicrobial'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3uKxwBRFCEH",
    "outputId": "e0d6bdbe-fdf3-4ee7-e54c-4a9bed39a5bc"
   },
   "outputs": [],
   "source": [
    "# Display all rows with Non-Antimicrobial activity\n",
    "non_antimicrobial_rows = df[df['Activity'] == 'Non-Antimicrobial']\n",
    "print(non_antimicrobial_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x8rBDco5GO9w",
    "outputId": "229d7325-17f8-4ab4-cf0f-24fc45c8d32a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Assuming the VotingClassifier model is already trained and available as `voting_model`\n",
    "\n",
    "def predict_antimicrobial(sequence):\n",
    "    # Create a DataFrame for the new input\n",
    "    input_data = pd.DataFrame({\n",
    "        'Sequence': [sequence],\n",
    "        'Sequence_Length': [len(sequence)],  # Calculate sequence length\n",
    "        'Source': ['unknown'],  # Default value for unknown source\n",
    "        'Protein_existence': ['unknown'],  # Default value for unknown existence\n",
    "        'Target_Organism': ['unknown'],  # Default value for unknown organism\n",
    "        'Hemolytic_activity': ['unknown'],  # Default value for unknown hemolytic activity\n",
    "        'Linear/Cyclic/Branched': ['unknown'],  # Default value for unknown structure\n",
    "        'Stereochemistry': ['unknown']  # Default value for unknown stereochemistry\n",
    "    })\n",
    "\n",
    "    # Convert 'Sequence' to k-mer representation\n",
    "    k = 3  # k value used during training\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=(k, k))\n",
    "    input_kmers = vectorizer.fit_transform(input_data['Sequence']).toarray()\n",
    "\n",
    "    # Create a DataFrame from k-mer features\n",
    "    kmers_df = pd.DataFrame(input_kmers, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Combine k-mer features with other features\n",
    "    input_combined = pd.concat([kmers_df, input_data[['Sequence_Length', 'Source',\n",
    "                                                       'Protein_existence',\n",
    "                                                       'Target_Organism',\n",
    "                                                       'Hemolytic_activity',\n",
    "                                                       'Linear/Cyclic/Branched',\n",
    "                                                       'Stereochemistry']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Encode categorical variables (use the same approach as training)\n",
    "    input_encoded = pd.get_dummies(input_combined, columns=['Source', 'Protein_existence',\n",
    "                                                             'Target_Organism',\n",
    "                                                             'Hemolytic_activity',\n",
    "                                                             'Linear/Cyclic/Branched',\n",
    "                                                             'Stereochemistry'], drop_first=True)\n",
    "\n",
    "    # Align input data with the training data\n",
    "    input_encoded = input_encoded.reindex(columns=X_resampled.columns, fill_value=0)\n",
    "\n",
    "    # Make predictions\n",
    "    prediction = voting_model.predict(input_encoded)\n",
    "    return prediction[0]  # Return the prediction result\n",
    "\n",
    "# Example usage\n",
    "user_input_sequence = input(\"Enter the sequence: \")\n",
    "result = predict_antimicrobial(user_input_sequence)\n",
    "print(f\"The prediction for the given sequence is: {'Antimicrobial' if result == 'Antimicrobial' else 'Non-Antimicrobial'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPQxerBGJuZ1",
    "outputId": "7f266e89-b65a-44d9-9ce5-7e28be70493e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Assuming the VotingClassifier model is already trained and available as `voting_model`\n",
    "\n",
    "def predict_antimicrobial(sequence):\n",
    "    # Create a DataFrame for the new input\n",
    "    input_data = pd.DataFrame({\n",
    "        'Sequence': [sequence],\n",
    "        'Sequence_Length': [len(sequence)],  # Calculate sequence length\n",
    "        'Source': ['unknown'],  # Default value for unknown source\n",
    "        'Protein_existence': ['unknown'],  # Default value for unknown existence\n",
    "        'Target_Organism': ['unknown'],  # Default value for unknown organism\n",
    "        'Hemolytic_activity': ['unknown'],  # Default value for unknown hemolytic activity\n",
    "        'Linear/Cyclic/Branched': ['unknown'],  # Default value for unknown structure\n",
    "        'Stereochemistry': ['unknown']  # Default value for unknown stereochemistry\n",
    "    })\n",
    "\n",
    "    # Convert 'Sequence' to k-mer representation\n",
    "    k = 3  # k value used during training\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=(k, k))\n",
    "    input_kmers = vectorizer.fit_transform(input_data['Sequence']).toarray()\n",
    "\n",
    "    # Create a DataFrame from k-mer features\n",
    "    kmers_df = pd.DataFrame(input_kmers, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Combine k-mer features with other features\n",
    "    input_combined = pd.concat([kmers_df, input_data[['Sequence_Length', 'Source',\n",
    "                                                       'Protein_existence',\n",
    "                                                       'Target_Organism',\n",
    "                                                       'Hemolytic_activity',\n",
    "                                                       'Linear/Cyclic/Branched',\n",
    "                                                       'Stereochemistry']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Encode categorical variables (use the same approach as training)\n",
    "    input_encoded = pd.get_dummies(input_combined, columns=['Source', 'Protein_existence',\n",
    "                                                             'Target_Organism',\n",
    "                                                             'Hemolytic_activity',\n",
    "                                                             'Linear/Cyclic/Branched',\n",
    "                                                             'Stereochemistry'], drop_first=True)\n",
    "\n",
    "    # Align input data with the training data\n",
    "    input_encoded = input_encoded.reindex(columns=X_resampled.columns, fill_value=0)\n",
    "\n",
    "    # Make predictions\n",
    "    prediction = voting_model.predict(input_encoded)\n",
    "    return prediction[0]  # Return the prediction result\n",
    "\n",
    "# Example usage\n",
    "user_input_sequence = input(\"Enter the sequence: \")\n",
    "result = predict_antimicrobial(user_input_sequence)\n",
    "print(f\"The prediction for the given sequence is: {'Antimicrobial' if result == 'Antimicrobial' else 'Non-Antimicrobial'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qpWmFTLVKrx_",
    "outputId": "80ca8672-b355-48a5-ad61-e68842af63c6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Assuming the VotingClassifier model is already trained and available as `voting_model`\n",
    "\n",
    "def predict_antimicrobial(sequence):\n",
    "    # Create a DataFrame for the new input\n",
    "    input_data = pd.DataFrame({\n",
    "        'Sequence': [sequence],\n",
    "        'Sequence_Length': [len(sequence)],  # Calculate sequence length\n",
    "        'Source': ['unknown'],  # Default value for unknown source\n",
    "        'Protein_existence': ['unknown'],  # Default value for unknown existence\n",
    "        'Target_Organism': ['unknown'],  # Default value for unknown organism\n",
    "        'Hemolytic_activity': ['unknown'],  # Default value for unknown hemolytic activity\n",
    "        'Linear/Cyclic/Branched': ['unknown'],  # Default value for unknown structure\n",
    "        'Stereochemistry': ['unknown']  # Default value for unknown stereochemistry\n",
    "    })\n",
    "\n",
    "    # Convert 'Sequence' to k-mer representation\n",
    "    k = 3  # k value used during training\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=(k, k))\n",
    "    input_kmers = vectorizer.fit_transform(input_data['Sequence']).toarray()\n",
    "\n",
    "    # Create a DataFrame from k-mer features\n",
    "    kmers_df = pd.DataFrame(input_kmers, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Combine k-mer features with other features\n",
    "    input_combined = pd.concat([kmers_df, input_data[['Sequence_Length', 'Source',\n",
    "                                                       'Protein_existence',\n",
    "                                                       'Target_Organism',\n",
    "                                                       'Hemolytic_activity',\n",
    "                                                       'Linear/Cyclic/Branched',\n",
    "                                                       'Stereochemistry']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Encode categorical variables (use the same approach as training)\n",
    "    input_encoded = pd.get_dummies(input_combined, columns=['Source', 'Protein_existence',\n",
    "                                                             'Target_Organism',\n",
    "                                                             'Hemolytic_activity',\n",
    "                                                             'Linear/Cyclic/Branched',\n",
    "                                                             'Stereochemistry'], drop_first=True)\n",
    "\n",
    "    # Align input data with the training data\n",
    "    input_encoded = input_encoded.reindex(columns=X_resampled.columns, fill_value=0)\n",
    "\n",
    "    # Make predictions\n",
    "    prediction = voting_model.predict(input_encoded)\n",
    "    return prediction[0]  # Return the prediction result\n",
    "\n",
    "# Example usage\n",
    "user_input_sequence = input(\"Enter the sequence: \")\n",
    "result = predict_antimicrobial(user_input_sequence)\n",
    "print(f\"The prediction for the given sequence is: {'Antimicrobial' if result == 'Antimicrobial' else 'Non-Antimicrobial'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSP0ZamV-SK5",
    "outputId": "2dae8ea0-388e-4776-bafa-f6584425e5fc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Assuming the VotingClassifier model is already trained and available as `voting_model`\n",
    "\n",
    "def predict_antimicrobial(sequence):\n",
    "    # Create a DataFrame for the new input\n",
    "    input_data = pd.DataFrame({\n",
    "        'Sequence': [sequence],\n",
    "        'Sequence_Length': [len(sequence)],  # Calculate sequence length\n",
    "        'Source': ['unknown'],  # Default value for unknown source\n",
    "        'Protein_existence': ['unknown'],  # Default value for unknown existence\n",
    "        'Target_Organism': ['unknown'],  # Default value for unknown organism\n",
    "        'Hemolytic_activity': ['unknown'],  # Default value for unknown hemolytic activity\n",
    "        'Linear/Cyclic/Branched': ['unknown'],  # Default value for unknown structure\n",
    "        'Stereochemistry': ['unknown']  # Default value for unknown stereochemistry\n",
    "    })\n",
    "\n",
    "    # Convert 'Sequence' to k-mer representation\n",
    "    k = 3  # k value used during training\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=(k, k))\n",
    "    input_kmers = vectorizer.fit_transform(input_data['Sequence']).toarray()\n",
    "\n",
    "    # Create a DataFrame from k-mer features\n",
    "    kmers_df = pd.DataFrame(input_kmers, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Combine k-mer features with other features\n",
    "    input_combined = pd.concat([kmers_df, input_data[['Sequence_Length', 'Source',\n",
    "                                                       'Protein_existence',\n",
    "                                                       'Target_Organism',\n",
    "                                                       'Hemolytic_activity',\n",
    "                                                       'Linear/Cyclic/Branched',\n",
    "                                                       'Stereochemistry']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Encode categorical variables (use the same approach as training)\n",
    "    input_encoded = pd.get_dummies(input_combined, columns=['Source', 'Protein_existence',\n",
    "                                                             'Target_Organism',\n",
    "                                                             'Hemolytic_activity',\n",
    "                                                             'Linear/Cyclic/Branched',\n",
    "                                                             'Stereochemistry'], drop_first=True)\n",
    "\n",
    "    # Align input data with the training data\n",
    "    input_encoded = input_encoded.reindex(columns=X_resampled.columns, fill_value=0)\n",
    "\n",
    "    # Make predictions\n",
    "    prediction = voting_model.predict(input_encoded)\n",
    "    return prediction[0]  # Return the prediction result\n",
    "\n",
    "# Example usage\n",
    "user_input_sequence = input(\"Enter the sequence: \")\n",
    "result = predict_antimicrobial(user_input_sequence)\n",
    "print(f\"The prediction for the given sequence is: {'Antimicrobial' if result == 'Antimicrobial' else 'Non-Antimicrobial'}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
